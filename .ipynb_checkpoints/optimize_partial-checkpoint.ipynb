{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/hyeryung/torch-tutorial\n",
      "/data/hyeryung/torch-tutorial\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/data/hyeryung/torch-tutorial')\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18#, ResNet18_Weights\n",
    "# model=resnet18()#weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1,1,28,28)\n",
    "labels=torch.rand(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.2566e-03, -9.9593e-03,  1.3915e-02,  2.7217e-03,  1.2451e-04],\n",
       "          [ 1.3813e-02,  9.0406e-03,  4.2393e-03,  2.4139e-02,  7.9914e-03],\n",
       "          [ 1.0118e-02,  2.8678e-03,  3.7796e-03,  1.8159e-02,  1.3566e-02],\n",
       "          [-1.9168e-03,  2.9289e-03,  5.4085e-03, -1.1618e-02,  1.3730e-02],\n",
       "          [ 1.9551e-02, -9.5472e-03,  2.1524e-02, -1.2041e-02,  2.9435e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1606e-03, -2.4089e-03, -3.5448e-03, -2.6400e-02, -1.8053e-02],\n",
       "          [ 7.0536e-03,  8.4262e-03, -9.5181e-03, -1.2046e-02, -8.1082e-04],\n",
       "          [ 2.2030e-02,  2.7097e-03,  7.1105e-03,  1.5525e-02,  2.5826e-02],\n",
       "          [-9.6161e-03, -6.3244e-03,  7.9929e-03, -1.6124e-03, -1.0930e-03],\n",
       "          [ 9.0177e-03,  7.3390e-03,  2.0177e-02,  1.6140e-02, -2.5510e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.1253e-04, -1.7554e-02, -1.5530e-02, -2.8584e-02, -2.4009e-02],\n",
       "          [ 1.4896e-04, -3.1858e-03, -2.6871e-02, -3.6048e-02, -4.8292e-02],\n",
       "          [-3.2851e-02, -3.4032e-02, -2.1367e-02, -3.0831e-02, -3.2239e-02],\n",
       "          [-2.9164e-02, -1.8840e-02, -1.4903e-02, -8.8171e-03, -3.5643e-02],\n",
       "          [-3.7661e-02, -1.7272e-02, -2.2644e-02, -1.4181e-03, -2.7998e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.9994e-02,  7.6142e-05,  1.3027e-02,  1.1285e-04,  1.4054e-02],\n",
       "          [ 1.9766e-03, -1.2560e-02,  1.1197e-02,  3.8896e-03,  1.3537e-02],\n",
       "          [ 1.7561e-02, -2.2432e-03, -9.3794e-04,  9.6607e-03,  1.1142e-02],\n",
       "          [ 2.0736e-02,  1.2523e-03, -1.1647e-02, -2.1632e-03,  1.5445e-02],\n",
       "          [ 7.6613e-03, -2.6850e-03,  2.5209e-02,  5.1072e-03, -5.7689e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.6805e-03, -1.8784e-02,  6.1019e-03,  2.1418e-03,  1.3373e-02],\n",
       "          [ 1.9424e-02,  2.5833e-02,  1.5290e-02,  3.0536e-02,  2.7362e-02],\n",
       "          [ 1.2742e-02, -9.9343e-03,  4.5970e-02,  9.7314e-03,  1.8237e-02],\n",
       "          [ 2.4274e-02,  1.5905e-02,  1.3290e-02,  1.7242e-02,  2.1766e-02],\n",
       "          [ 1.0350e-02,  2.4081e-02,  7.2822e-03,  1.6030e-02,  1.5307e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.3249e-03,  1.7635e-02,  1.9544e-02,  1.5609e-02,  1.2826e-03],\n",
       "          [ 1.3975e-02, -4.2566e-03,  2.2979e-02,  3.8329e-02,  1.7873e-02],\n",
       "          [ 2.7419e-02,  3.5044e-02,  1.6693e-02,  1.8684e-03,  1.9697e-02],\n",
       "          [ 1.6020e-02,  3.3300e-02,  9.5242e-03,  2.6863e-02,  4.2364e-03],\n",
       "          [ 3.9182e-02, -4.9622e-03,  1.1076e-02,  3.5390e-02,  1.2135e-02]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_edit=[0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight.grad[indices_to_edit,:]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.step() #gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0127, -0.1863,  0.0520,  0.1322, -0.0828],\n",
       "          [ 0.0398,  0.1881,  0.1059,  0.1514,  0.0359],\n",
       "          [-0.1644,  0.0442,  0.0250, -0.1809, -0.0954],\n",
       "          [ 0.0611, -0.1604, -0.1047,  0.1716,  0.1502],\n",
       "          [ 0.1208, -0.1971,  0.1143,  0.1076,  0.1216]]],\n",
       "\n",
       "\n",
       "        [[[-0.0340,  0.1937,  0.1843,  0.1529, -0.0337],\n",
       "          [ 0.0396,  0.0219,  0.0904, -0.0902,  0.0274],\n",
       "          [ 0.1485, -0.1981, -0.1518, -0.0209,  0.0684],\n",
       "          [ 0.1242,  0.0603,  0.0886, -0.0621,  0.0464],\n",
       "          [-0.0851, -0.1875,  0.0569,  0.0067, -0.0429]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1586,  0.0141, -0.1250,  0.0012, -0.0799],\n",
       "          [-0.0078,  0.1742,  0.1380, -0.0759,  0.1028],\n",
       "          [ 0.1334,  0.1796,  0.0017, -0.0417, -0.0762],\n",
       "          [-0.1949, -0.1304,  0.0328, -0.0392, -0.0266],\n",
       "          [ 0.1866,  0.0260,  0.0827, -0.0064,  0.1003]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1701,  0.1287,  0.0909, -0.1440,  0.1809],\n",
       "          [-0.0844, -0.1223, -0.1492,  0.0800,  0.1167],\n",
       "          [ 0.1401, -0.0712, -0.1481, -0.1668, -0.1701],\n",
       "          [-0.0528,  0.0989, -0.1951,  0.1651, -0.0431],\n",
       "          [-0.0996,  0.0519,  0.1948,  0.1733,  0.0540]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1405,  0.1017, -0.0834, -0.1898, -0.1005],\n",
       "          [ 0.0574,  0.0309, -0.1904, -0.1313,  0.1013],\n",
       "          [-0.1114,  0.0553,  0.0972,  0.0861, -0.1592],\n",
       "          [ 0.1089,  0.1171,  0.0802,  0.1576,  0.0945],\n",
       "          [-0.0471,  0.1305,  0.1356,  0.1821,  0.0899]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1281,  0.0314,  0.1464, -0.0665,  0.0554],\n",
       "          [ 0.1534, -0.1934,  0.0410,  0.0514,  0.0525],\n",
       "          [-0.0109,  0.0805, -0.0900, -0.0135, -0.0367],\n",
       "          [-0.1605, -0.1271,  0.1337,  0.1037,  0.0357],\n",
       "          [ 0.0870,  0.0093, -0.1187,  0.1423, -0.1862]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0127, -0.1863,  0.0520,  0.1322, -0.0828],\n",
       "          [ 0.0398,  0.1881,  0.1059,  0.1514,  0.0359],\n",
       "          [-0.1644,  0.0442,  0.0250, -0.1809, -0.0954],\n",
       "          [ 0.0611, -0.1604, -0.1047,  0.1716,  0.1502],\n",
       "          [ 0.1208, -0.1971,  0.1143,  0.1076,  0.1216]]],\n",
       "\n",
       "\n",
       "        [[[-0.0340,  0.1937,  0.1843,  0.1529, -0.0337],\n",
       "          [ 0.0396,  0.0219,  0.0904, -0.0902,  0.0274],\n",
       "          [ 0.1485, -0.1981, -0.1518, -0.0209,  0.0684],\n",
       "          [ 0.1242,  0.0603,  0.0886, -0.0621,  0.0464],\n",
       "          [-0.0851, -0.1875,  0.0569,  0.0067, -0.0429]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1586,  0.0141, -0.1250,  0.0012, -0.0799],\n",
       "          [-0.0078,  0.1742,  0.1380, -0.0759,  0.1028],\n",
       "          [ 0.1334,  0.1796,  0.0017, -0.0417, -0.0762],\n",
       "          [-0.1949, -0.1304,  0.0328, -0.0392, -0.0266],\n",
       "          [ 0.1866,  0.0260,  0.0827, -0.0064,  0.1003]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1698,  0.1287,  0.0908, -0.1440,  0.1808],\n",
       "          [-0.0845, -0.1222, -0.1493,  0.0799,  0.1166],\n",
       "          [ 0.1400, -0.0712, -0.1481, -0.1669, -0.1702],\n",
       "          [-0.0531,  0.0989, -0.1950,  0.1651, -0.0433],\n",
       "          [-0.0997,  0.0519,  0.1946,  0.1732,  0.0540]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1405,  0.1019, -0.0835, -0.1899, -0.1006],\n",
       "          [ 0.0572,  0.0307, -0.1906, -0.1316,  0.1010],\n",
       "          [-0.1115,  0.0554,  0.0967,  0.0860, -0.1594],\n",
       "          [ 0.1087,  0.1169,  0.0801,  0.1574,  0.0942],\n",
       "          [-0.0472,  0.1303,  0.1355,  0.1820,  0.0897]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1281,  0.0312,  0.1462, -0.0666,  0.0554],\n",
       "          [ 0.1533, -0.1933,  0.0408,  0.0511,  0.0523],\n",
       "          [-0.0112,  0.0801, -0.0902, -0.0135, -0.0369],\n",
       "          [-0.1606, -0.1274,  0.1336,  0.1034,  0.0356],\n",
       "          [ 0.0866,  0.0093, -0.1188,  0.1419, -0.1863]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"mps\" if torch.backends.mps.is_available()\n",
    "          else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module): # inherits nn.Module\n",
    "  def __init__(self): # define layers in constructor\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x): # specify how data will pass through the network\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "model = NeuralNetwork().to(device) # move to device (gpu)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "linear_relu_stack.0.bias\n",
      "linear_relu_stack.2.weight\n",
      "linear_relu_stack.2.bias\n",
      "linear_relu_stack.4.weight\n",
      "linear_relu_stack.4.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1,1,28,28).to(device)\n",
    "labels=torch.rand(1,10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # for the first argument, pass tensor to optimize.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(data)\n",
    "loss = loss_fn(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0173, 0.0168, 0.0098,  ..., 0.0082, 0.0111, 0.0059],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())['linear_relu_stack.0.weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "linear_relu_stack.0.bias\n",
      "linear_relu_stack.2.weight\n",
      "linear_relu_stack.2.bias\n",
      "linear_relu_stack.4.weight\n",
      "linear_relu_stack.4.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(model.named_parameters())['linear_relu_stack.0.weight'].grad[1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())['linear_relu_stack.0.weight'].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# deep copy를 안해주면, view가 연결되기 때문에 값이 변하는게 안보였던 것!\n",
    "old_weights = copy.deepcopy(dict(model.named_parameters())['linear_relu_stack.0.weight'].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = dict(model.named_parameters())['linear_relu_stack.0.weight'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0013, -0.0046, -0.0237,  ...,  0.0243,  0.0185, -0.0122],\n",
       "        [-0.0800, -0.0202, -0.0305,  ..., -0.0264, -0.0352,  0.0079],\n",
       "        [ 0.0313, -0.0036,  0.0070,  ..., -0.0204, -0.0189,  0.0055],\n",
       "        ...,\n",
       "        [-0.0269, -0.0303,  0.0251,  ...,  0.0181,  0.0021,  0.0317],\n",
       "        [-0.0238,  0.0126,  0.0152,  ..., -0.0167, -0.0051,  0.0120],\n",
       "        [-0.0268,  0.0282,  0.0177,  ...,  0.0073,  0.0039,  0.0012]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0013, -0.0046, -0.0237,  ...,  0.0243,  0.0185, -0.0122],\n",
       "        [-0.0800, -0.0202, -0.0305,  ..., -0.0264, -0.0352,  0.0079],\n",
       "        [ 0.0313, -0.0036,  0.0070,  ..., -0.0204, -0.0189,  0.0055],\n",
       "        ...,\n",
       "        [-0.0269, -0.0303,  0.0251,  ...,  0.0181,  0.0021,  0.0317],\n",
       "        [-0.0238,  0.0126,  0.0152,  ..., -0.0167, -0.0051,  0.0120],\n",
       "        [-0.0268,  0.0282,  0.0177,  ...,  0.0073,  0.0039,  0.0012]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_weights[1] == new_weights[1]).sum() == len(old_weights[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "          else \"mps\" if torch.backends.mps.is_available()\n",
    "          else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module): # inherits nn.Module\n",
    "  def __init__(self): # define layers in constructor\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x): # specify how data will pass through the network\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "model = NeuralNetwork().to(device) # move to device (gpu)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight\n",
      "linear_relu_stack.0.bias\n",
      "linear_relu_stack.2.weight\n",
      "linear_relu_stack.2.bias\n",
      "linear_relu_stack.4.weight\n",
      "linear_relu_stack.4.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(1,1,28,28).to(device)\n",
    "labels=torch.rand(1,10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach()."
     ]
    }
   ],
   "source": [
    "list(model.parameters())[0][:,[1,3,5,7,9]].requires_grad =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0130, -0.0060,  0.0142,  ..., -0.0121, -0.0202,  0.0099],\n",
       "        [-0.0191,  0.0270, -0.0044,  ..., -0.0115,  0.0292, -0.0160],\n",
       "        [-0.0214,  0.0077,  0.0260,  ..., -0.0299,  0.0182,  0.0287],\n",
       "        ...,\n",
       "        [ 0.0173, -0.0343, -0.0345,  ..., -0.0233, -0.0209, -0.0237],\n",
       "        [ 0.0066, -0.0080,  0.0267,  ..., -0.0094,  0.0327, -0.0266],\n",
       "        [ 0.0159,  0.0046,  0.0001,  ...,  0.0133,  0.0022,  0.0106]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # for the first argument, pass tensor to optimize.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# optimizer = torch.optim.SGD(model.parameters(), lr=1) \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/.local/share/virtualenvs/transformers-tutorial-g9NgLH4G/lib/python3.9/site-packages/torch/optim/sgd.py:27\u001b[0m, in \u001b[0;36mSGD.__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nesterov \u001b[38;5;129;01mand\u001b[39;00m (momentum \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dampening \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNesterov momentum requires a momentum and zero dampening\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/transformers-tutorial-g9NgLH4G/lib/python3.9/site-packages/torch/optim/optimizer.py:192\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    189\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/transformers-tutorial-g9NgLH4G/lib/python3.9/site-packages/torch/optim/optimizer.py:515\u001b[0m, in \u001b[0;36mOptimizer.add_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer can only optimize Tensors, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut one of the params is \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtypename(param))\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (param\u001b[38;5;241m.\u001b[39mis_leaf \u001b[38;5;129;01mor\u001b[39;00m param\u001b[38;5;241m.\u001b[39mretains_grad):\n\u001b[0;32m--> 515\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt optimize a non-leaf Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, default \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m required \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_group:\n",
      "\u001b[0;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # for the first argument, pass tensor to optimize.\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1) \n",
    "optimizer = torch.optim.SGD([list(model.parameters())[0][:,[1,3,5,7,9]]], lr=1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
